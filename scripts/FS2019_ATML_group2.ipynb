{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATML Project Report\n",
    "\n",
    "### Group 2\n",
    "Members: LÃ©onard Barras & Nathan Gyger\n",
    "\n",
    "Github: https://github.com/svapili/FS2019_ATML_Group2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma image classification\n",
    "### Goal:\n",
    "Implement a deep learning algorithm to classify mole pictures as benign or malignant using the [ISIC database](https://isic-archive.com/).\n",
    "\n",
    "### Approach description:\n",
    "TODO: write a description\n",
    "- Class imbalance => data augmentation\n",
    "- Images => CNN as a logical choice\n",
    "- Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "TODO: add accuracy table for different parameters\n",
    "\n",
    "## Learning curve\n",
    "TODO: add graphic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"Hello from cluster!\")\n",
    "print(\"Available GPU: \", torch.cuda.get_device_name(0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import util\n",
    "import csv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "import dataSplitter\n",
    "import loader\n",
    "import dataAugmenter\n",
    "import SimpleNet\n",
    "import train\n",
    "import test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths definitions\n",
    "Path = '/var/tmp/'\n",
    "dataDir = Path + 'ISIC-images'\n",
    "trainDir = Path + 'ISIC-images/train/'\n",
    "testDir = Path + 'ISIC-images/test/'\n",
    "valDir = Path + 'ISIC-images/val/'\n",
    "\n",
    "\n",
    "# Paths definitions for saving results and model state\n",
    "my_path = os.getcwd()\n",
    "dir = os.path.dirname(my_path)\n",
    "results_dir = dir + '/results'\n",
    "modelstate_dir = '/var/tmp/modelstate'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(modelstate_dir):\n",
    "    os.makedirs(modelstate_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "newDataSplit = False # Set to true to split the data randomly again. Data have first to be downloaded and extracted with data_extractor.py\n",
    "dataPreprocessing = False # Set to true to resize and augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can use CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs a new random split of the data\n",
    "# Data have first to be downloaded and extracted with data_extractor.py\n",
    "if (newDataSplit):\n",
    "    testRatio = .1\n",
    "    valRatio = .1\n",
    "    split(trainDir, testDir, valDir, testRatio, valRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data (resizing and augmenting)\n",
    "if (dataPreprocessing):\n",
    "    preprocessData([trainDir, testDir, valDir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloaders objects\n",
    "image_datasets, dataloaders = loader.melanomaDataLoader(dataDir, batch_size=batch_size)\n",
    "\n",
    "# Get dataset objects sizes\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test', 'val']}\n",
    "print(\"Size of the dataset objects: \", dataset_sizes)\n",
    "\n",
    "# Get the class names\n",
    "class_names = image_datasets['train'].classes\n",
    "print(\"Images class names: \", class_names)\n",
    "\n",
    "# Visualize sample images\n",
    "print(\"Sample images:\")\n",
    "loader.showSample(dataloaders, dataset_sizes, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# SELECT MODEL\n",
    "###############################\n",
    "model = models.AlexNet(num_classes=2)\n",
    "#model = models.resnet101()\n",
    "\n",
    "###############################\n",
    "# SELECT OPTIMIZER\n",
    "###############################\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "###############################\n",
    "# SELECT LOSS FUNCTION\n",
    "###############################\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "debug_training_status = False\n",
    "\n",
    "\n",
    "saving = True\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Epoch Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test train and test function\n",
    "if debug_training_status is True:\n",
    "    train_loss, train_accuracy = train.train(model, dataloaders['train'], optimizer, loss_fn, device, status = debug_training_status)\n",
    "    val_loss, val_accuracy, a, b, c, d  = test_.test(model, dataloaders['val'], loss_fn, device)\n",
    "    test_loss, test_accuracy, a, b, c, d = test_.test(model, dataloaders['test'], loss_fn, device)\n",
    "    print('Test training: train_loss: {:.4f}, train_accuracy: {:.4f}, val_loss: {:.4f}, val_accuracy: {:.4f}, test_loss: {:.4f}, test_accuracy: {:.4f}'.format(\n",
    "        train_loss,\n",
    "        train_accuracy,\n",
    "        val_loss,\n",
    "        val_accuracy,\n",
    "        test_loss,\n",
    "        test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import time\n",
    "    \n",
    "    train_losses, train_accuracies = ['train_losses'], ['train_accuracies']\n",
    "    val_losses, val_accuracies = ['val_losses'], ['val_accuracies']\n",
    "    time_epoch = ['execution time']\n",
    "    \n",
    "    TPs = ['True Positives']\n",
    "    TNs = ['True Negatives']\n",
    "    FPs = ['False Positives']\n",
    "    FNs = ['False Negatives']\n",
    "    \n",
    "    config  = model._get_name() + \" \" + \"_bs=\" + str(batch_size)\n",
    "    \n",
    "    ##############################\n",
    "    # Training Epochs            #\n",
    "    ##############################\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time_epoch = time.time()\n",
    "        \n",
    "        train_loss, train_accuracy = train.train(model, dataloaders['train'], optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy, TP, TN, FP, FN  = test_.test(model, dataloaders['val'], loss_fn, device) \n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        TPs.append(TP)\n",
    "        TNs.append(TN)\n",
    "        FPs.append(FP)\n",
    "        FNs.append(FN)\n",
    "        \n",
    "        # TIME CALCULATION\n",
    "        time_last_epoch = time.time() - start_time_epoch\n",
    "        time_epoch.append(time_last_epoch)\n",
    "        \n",
    "        # OTHER METRICS\n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}: train_loss: {:.4f}, train_accuracy: {:.4f}, val_loss: {:.4f}, val_accuracy: {:.4f}, epoch execution time: {:.4f}'.format(\n",
    "            epoch + 1, n_epochs,\n",
    "            train_losses[-1],\n",
    "            train_accuracies[-1],\n",
    "            val_losses[-1],\n",
    "            val_accuracies[-1],\n",
    "            time_epoch[-1]))\n",
    "        \n",
    "        print('True Positive: {}, True Negative: {}, False Positives: {}, False Negative: {}'.format(\n",
    "            TPs[-1],\n",
    "            TNs[-1],\n",
    "            FPs[-1],\n",
    "            FNs[-1]))\n",
    "\n",
    "    ##############################\n",
    "    # Saving results             #\n",
    "    ##############################\n",
    "\n",
    "        if saving is True: #and (epoch+1) % 5 == 0:\n",
    "            print('...saving...')\n",
    "            name = config + '_' + loss_fn.__str__() + '_lr=' + str(learning_rate) + '_' +(optimizer.__str__()).split(' ')[0]\n",
    "\n",
    "            #remove old results\n",
    "            for filename in glob.glob(results_dir + '/' + name + '*'):\n",
    "                os.remove(filename)\n",
    "            for filename in glob.glob(modelstate_dir + '/' + name + '*'):\n",
    "                os.remove(filename)\n",
    "\n",
    "            name = name + '_Epoch_' + str(epoch)\n",
    "\n",
    "            # save model weights\n",
    "            torch.save(model.state_dict(), modelstate_dir + '/' + name + '.pth')\n",
    "\n",
    "            # save results per epoch\n",
    "            path = results_dir + '/' + name + '.csv'\n",
    "            with open(path, 'a') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                writer.writerow(train_losses)\n",
    "                writer.writerow(train_accuracies)\n",
    "                writer.writerow(val_losses)\n",
    "                writer.writerow(val_accuracies)\n",
    "                writer.writerow(time_epoch)\n",
    "                writer.writerow(TPs)\n",
    "                writer.writerow(TNs)\n",
    "                writer.writerow(FPs)\n",
    "                writer.writerow(FNs)\n",
    "            csvFile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
